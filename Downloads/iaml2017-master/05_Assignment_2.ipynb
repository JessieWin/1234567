{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introductory applied machine learning (INFR10069)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marking Breakdown\n",
    "\n",
    "**70-100%** results/answer correct plus extra achievement at understanding or analysis of results. Clear explanations, evidence of creative or deeper thought will contribute to a higher grade.\n",
    "\n",
    "**60-69%** results/answer correct or nearly correct and well explained.\n",
    "\n",
    "**50-59%** results/answer in right direction but significant errors.\n",
    "\n",
    "**40-49%** some evidence that the student has gained some understanding, but not answered the questions\n",
    "properly.\n",
    "\n",
    "**0-39%** serious error or slack work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mechanics\n",
    "\n",
    "Fill out this notebook, save it, and **submit it electronically as described below.**\n",
    "\n",
    "On a DICE environment, open the terminal, navigate to the location of this notebook, and submit this notebook file using the following command:\n",
    "\n",
    "`submit iaml cw1 05_Assignment_2.ipynb`\n",
    "\n",
    "What actually happens in the background is that your file is placed in a folder available to markers. If you submit a file with the same name into the same location, **it will *overwrite* your previous submission**. You can check the status of your submissions with the `show_submissions` command.\n",
    "\n",
    "**Distance Learners:** To copy your work up to DICE (such that you can use the `submit` command) you can use `scp` or `rsync` (you may need to install these yourself). You can copy files up using `student.ssh.inf.ed.ac.uk`, then ssh in to submit, e.g. (in a unix terminal):\n",
    "```\n",
    "filename=05_Assignment_2.ipynb\n",
    "local_scp_filepath=~/git/iaml2017/${filename}\n",
    "UUN=s0816700\n",
    "server_address=student.ssh.inf.ed.ac.uk\n",
    "scp -r ${local_scp_filepath} ${UUN}@${server_address}:${filename}\n",
    "# rsync -rl ${local_scp_filepath} ${UUN}@${server_address}:${filename}\n",
    "ssh ${UUN}@${server_address}\n",
    "ssh student.login\n",
    "submit iaml cw1 05_Assignment_2.ipynb\n",
    "```\n",
    "\n",
    "**Late submissions:** The policy stated in the School of Informatics MSc Degree Guide is that normally you will not be allowed to submit coursework late. See http://www.inf.ed.ac.uk/teaching/years/msc/courseguide10.html#exam for exceptions to this, e.g. in case of serious medical illness or serious personal problems.\n",
    "\n",
    "**Collaboration:** You may discuss the assignment with your colleagues, provided that the writing that you submit is entirely your own. That is, you should NOT borrow actual text or code from other students. We ask that you provide a list of the people who you've had discussions with (if any).\n",
    "\n",
    "**Resubmission:** If you submit your file again, the previous submission is **overwritten**. We will mark the version that is in the submission folder at the deadline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Instructions\n",
    "\n",
    "1. You *MUST* have your environment set up as in the [README](https://github.com/JamesOwers/iaml2017) and you *must activate this environment before running this notebook*:\n",
    "```\n",
    "source activate iaml\n",
    "cd iaml_2017\n",
    "jupyter notebook\n",
    "# Navigate to this file\n",
    "```\n",
    "\n",
    "1. Wherever you are required to produce code you should use code cells, otherwise you should use markdown cells to report results and explain answers.\n",
    "\n",
    "1. The .csv files that you will be using are located at `./datasets` (the `datasets` directory is adjacent to this file).\n",
    "\n",
    "1. **IMPORTANT:** Keep your answers brief and concise. Most written questions can be answered with 2-3 lines of explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Execute the cell below to import all packages you will be using in the rest of the assignemnt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score, explained_variance_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_predict\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of the dataset\n",
    "This assignment is based on the automobile pricing dataset. Our goal will be to predict the price of automobiles based on various attributes. This data set consists of three types of entities: \n",
    "\n",
    "1. The specification of an automobile in terms of various characteristics \n",
    "\n",
    "1. Assigned insurance risk rating \n",
    "   * this rating corresponds to the degree to which the auto is more risky than its price indicates. Cars are initially assigned a risk factor symbol associated with its price. Then, if it is more risky (or less), this symbol is adjusted by moving it up (or down) the scale. Actuaries call this process ”symboling”. A value of +3 indicates that the auto is risky, -3 that it is probably pretty safe. \n",
    "\n",
    "1. Normalized losses in use as compared to other cars\n",
    "  * the third factor is the relative average loss payment per insured vehicle year. This value is normalized for all autos within a particular size classification (two door small, station wagons, sports/speciality, etc...), and represents the average loss per car per year (avg_loss/car/year). \n",
    "\n",
    "\n",
    "To save you time and to make the problem manageable with limited computational resources, we preprocessed the original dataset. We removed any instances that had one or more missing values and randomized the data set. The resulting representation is much more compact and can be used directly to perform our experiments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Simple Linear Regression [50%]\n",
    "We will begin by studying a simple Linear Regression model. Such a model will consider the relationship between a dependent (response) variable and only one independent (explanatory) variable. When applying machine learning in practice it can be prudent to start out simple in order to get a feeling for the dataset and for any potential difficulties that might warrant a more sophisticated model. In this Section we will consider one independent variable (i.e. feature) `engine-power` against the dependent variable (i.e. target) `price`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.1 --- [1 mark] ==========\n",
    "Load the dataset `train_auto_numeric.csv` into a pandas DataFrame called `auto_numeric`. Display the number of data points and attributes in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data_path = os.path.join(os.getcwd(), 'datasets', 'train_auto_numeric.csv')\n",
    "auto_numeric = pd.read_csv(data_path, delimiter = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.2 --- [1 mark] ==========\n",
    "Display the first 8 instances of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>normalized-losses</th>\n",
       "      <th>wheel-base</th>\n",
       "      <th>length</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>engine-size</th>\n",
       "      <th>bore</th>\n",
       "      <th>stroke</th>\n",
       "      <th>compression-ratio</th>\n",
       "      <th>engine-power</th>\n",
       "      <th>peak-rpm</th>\n",
       "      <th>city-mpg</th>\n",
       "      <th>highway-mpg</th>\n",
       "      <th>mean-effective-pressure</th>\n",
       "      <th>torque</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>164.0</td>\n",
       "      <td>99.8</td>\n",
       "      <td>176.6</td>\n",
       "      <td>66.2</td>\n",
       "      <td>54.3</td>\n",
       "      <td>8.85</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>10.0</td>\n",
       "      <td>102000.0</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>40.52</td>\n",
       "      <td>57.68</td>\n",
       "      <td>13950.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110.0</td>\n",
       "      <td>99.4</td>\n",
       "      <td>162.4</td>\n",
       "      <td>66.4</td>\n",
       "      <td>54.3</td>\n",
       "      <td>15.18</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>8.0</td>\n",
       "      <td>115000.0</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>47.39</td>\n",
       "      <td>59.59</td>\n",
       "      <td>17450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>158.0</td>\n",
       "      <td>105.8</td>\n",
       "      <td>192.7</td>\n",
       "      <td>71.4</td>\n",
       "      <td>51.6</td>\n",
       "      <td>15.18</td>\n",
       "      <td>3.94</td>\n",
       "      <td>2.80</td>\n",
       "      <td>8.5</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>4400.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>3344.79</td>\n",
       "      <td>17710.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.0</td>\n",
       "      <td>86.6</td>\n",
       "      <td>158.7</td>\n",
       "      <td>67.7</td>\n",
       "      <td>55.9</td>\n",
       "      <td>13.74</td>\n",
       "      <td>3.13</td>\n",
       "      <td>3.50</td>\n",
       "      <td>7.8</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>5600.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>44.74</td>\n",
       "      <td>68.97</td>\n",
       "      <td>23875.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>192.0</td>\n",
       "      <td>101.2</td>\n",
       "      <td>176.8</td>\n",
       "      <td>64.8</td>\n",
       "      <td>54.3</td>\n",
       "      <td>8.67</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2.80</td>\n",
       "      <td>8.8</td>\n",
       "      <td>101000.0</td>\n",
       "      <td>5800.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>44.78</td>\n",
       "      <td>53.48</td>\n",
       "      <td>16430.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>194.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>190.9</td>\n",
       "      <td>71.4</td>\n",
       "      <td>58.7</td>\n",
       "      <td>8.67</td>\n",
       "      <td>3.78</td>\n",
       "      <td>3.90</td>\n",
       "      <td>22.5</td>\n",
       "      <td>101000.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1330.28</td>\n",
       "      <td>16925.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>188.0</td>\n",
       "      <td>101.2</td>\n",
       "      <td>176.8</td>\n",
       "      <td>64.8</td>\n",
       "      <td>54.3</td>\n",
       "      <td>26.58</td>\n",
       "      <td>3.31</td>\n",
       "      <td>3.19</td>\n",
       "      <td>9.0</td>\n",
       "      <td>121000.0</td>\n",
       "      <td>4250.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>7.19</td>\n",
       "      <td>377.06</td>\n",
       "      <td>20970.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>150.0</td>\n",
       "      <td>101.2</td>\n",
       "      <td>176.8</td>\n",
       "      <td>64.8</td>\n",
       "      <td>56.1</td>\n",
       "      <td>26.58</td>\n",
       "      <td>3.03</td>\n",
       "      <td>3.19</td>\n",
       "      <td>8.0</td>\n",
       "      <td>134000.0</td>\n",
       "      <td>4400.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>57.37</td>\n",
       "      <td>48.20</td>\n",
       "      <td>21105.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   normalized-losses  wheel-base  length  width  height  engine-size  bore  \\\n",
       "0              164.0        99.8   176.6   66.2    54.3         8.85  3.19   \n",
       "1              110.0        99.4   162.4   66.4    54.3        15.18  3.19   \n",
       "2              158.0       105.8   192.7   71.4    51.6        15.18  3.94   \n",
       "3              106.0        86.6   158.7   67.7    55.9        13.74  3.13   \n",
       "4              192.0       101.2   176.8   64.8    54.3         8.67  3.50   \n",
       "5              194.0       110.0   190.9   71.4    58.7         8.67  3.78   \n",
       "6              188.0       101.2   176.8   64.8    54.3        26.58  3.31   \n",
       "7              150.0       101.2   176.8   64.8    56.1        26.58  3.03   \n",
       "\n",
       "   stroke  compression-ratio  engine-power  peak-rpm  city-mpg  highway-mpg  \\\n",
       "0    3.40               10.0      102000.0    5500.0      24.0         30.0   \n",
       "1    3.40                8.0      115000.0    5500.0      18.0         22.0   \n",
       "2    2.80                8.5       70000.0    4400.0      28.0         30.0   \n",
       "3    3.50                7.8      140000.0    5600.0      32.0         20.0   \n",
       "4    2.80                8.8      101000.0    5800.0      23.0         29.0   \n",
       "5    3.90               22.5      101000.0    6000.0      47.0         53.0   \n",
       "6    3.19                9.0      121000.0    4250.0      21.0         28.0   \n",
       "7    3.19                8.0      134000.0    4400.0      28.0         37.0   \n",
       "\n",
       "   mean-effective-pressure   torque    price  \n",
       "0                    40.52    57.68  13950.0  \n",
       "1                    47.39    59.59  17450.0  \n",
       "2                     0.85  3344.79  17710.0  \n",
       "3                    44.74    68.97  23875.0  \n",
       "4                    44.78    53.48  16430.0  \n",
       "5                     1.80  1330.28  16925.0  \n",
       "6                     7.19   377.06  20970.0  \n",
       "7                    57.37    48.20  21105.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code goes here\n",
    "auto_numeric.head(8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.3 --- [1 mark] ==========\n",
    "Display the summary statistics for the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>normalized-losses</th>\n",
       "      <th>wheel-base</th>\n",
       "      <th>length</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>engine-size</th>\n",
       "      <th>bore</th>\n",
       "      <th>stroke</th>\n",
       "      <th>compression-ratio</th>\n",
       "      <th>engine-power</th>\n",
       "      <th>peak-rpm</th>\n",
       "      <th>city-mpg</th>\n",
       "      <th>highway-mpg</th>\n",
       "      <th>mean-effective-pressure</th>\n",
       "      <th>torque</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>121.955975</td>\n",
       "      <td>98.559748</td>\n",
       "      <td>171.698113</td>\n",
       "      <td>65.729560</td>\n",
       "      <td>53.925157</td>\n",
       "      <td>14.056352</td>\n",
       "      <td>3.294528</td>\n",
       "      <td>3.219874</td>\n",
       "      <td>10.446855</td>\n",
       "      <td>98528.301887</td>\n",
       "      <td>5072.012579</td>\n",
       "      <td>27.113208</td>\n",
       "      <td>32.327044</td>\n",
       "      <td>46.180503</td>\n",
       "      <td>200.055031</td>\n",
       "      <td>11684.723270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>39.434186</td>\n",
       "      <td>5.803361</td>\n",
       "      <td>12.656791</td>\n",
       "      <td>2.292021</td>\n",
       "      <td>2.410446</td>\n",
       "      <td>17.143568</td>\n",
       "      <td>0.296959</td>\n",
       "      <td>0.381833</td>\n",
       "      <td>4.414796</td>\n",
       "      <td>34123.715967</td>\n",
       "      <td>549.988239</td>\n",
       "      <td>7.848229</td>\n",
       "      <td>8.231998</td>\n",
       "      <td>28.780966</td>\n",
       "      <td>513.289289</td>\n",
       "      <td>6744.910579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>65.000000</td>\n",
       "      <td>86.600000</td>\n",
       "      <td>141.100000</td>\n",
       "      <td>60.300000</td>\n",
       "      <td>49.400000</td>\n",
       "      <td>3.390000</td>\n",
       "      <td>2.540000</td>\n",
       "      <td>2.070000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>48000.000000</td>\n",
       "      <td>4150.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>19.400000</td>\n",
       "      <td>5118.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>93.000000</td>\n",
       "      <td>94.500000</td>\n",
       "      <td>163.400000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>6.960000</td>\n",
       "      <td>3.050000</td>\n",
       "      <td>3.070000</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>69000.000000</td>\n",
       "      <td>4800.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>26.500000</td>\n",
       "      <td>21.775000</td>\n",
       "      <td>34.140000</td>\n",
       "      <td>7372.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>110.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>171.700000</td>\n",
       "      <td>65.400000</td>\n",
       "      <td>54.100000</td>\n",
       "      <td>9.030000</td>\n",
       "      <td>3.270000</td>\n",
       "      <td>3.270000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>92000.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>49.800000</td>\n",
       "      <td>55.900000</td>\n",
       "      <td>9233.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>145.000000</td>\n",
       "      <td>101.200000</td>\n",
       "      <td>177.800000</td>\n",
       "      <td>66.500000</td>\n",
       "      <td>55.600000</td>\n",
       "      <td>14.885000</td>\n",
       "      <td>3.580000</td>\n",
       "      <td>3.410000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>116000.000000</td>\n",
       "      <td>5450.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>68.495000</td>\n",
       "      <td>119.990000</td>\n",
       "      <td>14719.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>256.000000</td>\n",
       "      <td>115.600000</td>\n",
       "      <td>202.600000</td>\n",
       "      <td>71.700000</td>\n",
       "      <td>59.800000</td>\n",
       "      <td>174.160000</td>\n",
       "      <td>3.940000</td>\n",
       "      <td>4.170000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>99.850000</td>\n",
       "      <td>3912.870000</td>\n",
       "      <td>42056.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       normalized-losses  wheel-base      length       width      height  \\\n",
       "count         159.000000  159.000000  159.000000  159.000000  159.000000   \n",
       "mean          121.955975   98.559748  171.698113   65.729560   53.925157   \n",
       "std            39.434186    5.803361   12.656791    2.292021    2.410446   \n",
       "min            65.000000   86.600000  141.100000   60.300000   49.400000   \n",
       "25%            93.000000   94.500000  163.400000   64.000000   52.000000   \n",
       "50%           110.000000   97.000000  171.700000   65.400000   54.100000   \n",
       "75%           145.000000  101.200000  177.800000   66.500000   55.600000   \n",
       "max           256.000000  115.600000  202.600000   71.700000   59.800000   \n",
       "\n",
       "       engine-size        bore      stroke  compression-ratio   engine-power  \\\n",
       "count   159.000000  159.000000  159.000000         159.000000     159.000000   \n",
       "mean     14.056352    3.294528    3.219874          10.446855   98528.301887   \n",
       "std      17.143568    0.296959    0.381833           4.414796   34123.715967   \n",
       "min       3.390000    2.540000    2.070000           7.000000   48000.000000   \n",
       "25%       6.960000    3.050000    3.070000           8.600000   69000.000000   \n",
       "50%       9.030000    3.270000    3.270000           9.000000   92000.000000   \n",
       "75%      14.885000    3.580000    3.410000           9.400000  116000.000000   \n",
       "max     174.160000    3.940000    4.170000          23.000000  200000.000000   \n",
       "\n",
       "          peak-rpm    city-mpg  highway-mpg  mean-effective-pressure  \\\n",
       "count   159.000000  159.000000   159.000000               159.000000   \n",
       "mean   5072.012579   27.113208    32.327044                46.180503   \n",
       "std     549.988239    7.848229     8.231998                28.780966   \n",
       "min    4150.000000   15.000000    18.000000                 0.490000   \n",
       "25%    4800.000000   22.000000    26.500000                21.775000   \n",
       "50%    5100.000000   26.000000    32.000000                49.800000   \n",
       "75%    5450.000000   31.000000    37.000000                68.495000   \n",
       "max    6600.000000   49.000000    54.000000                99.850000   \n",
       "\n",
       "            torque         price  \n",
       "count   159.000000    159.000000  \n",
       "mean    200.055031  11684.723270  \n",
       "std     513.289289   6744.910579  \n",
       "min      19.400000   5118.000000  \n",
       "25%      34.140000   7372.000000  \n",
       "50%      55.900000   9233.000000  \n",
       "75%     119.990000  14719.500000  \n",
       "max    3912.870000  42056.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code goes here\n",
    "auto_numeric.describe(include=[np.number])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.4 --- [2 marks] ==========\n",
    "Produce a scatter plot of `price` against `engine-power`. Label axes appropriately and include a title in your plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAScAAADkCAYAAADaUeLvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1172d4f90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your code goes here\n",
    "plt.figure(figsize=(4,3))\n",
    "plt.scatter(auto_numeric['engine-power'], auto_numeric['price'])\n",
    "plt.xlabel('engine-power', color = 'g')\n",
    "plt.ylabel('price', color = 'r')\n",
    "plt.title(\"price against engine-power\", size=20)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.5 --- [2 marks] ==========\n",
    "Do you think that engine-power alone is sufficient for predicting the price? Can you make any other observations on the data from the above plot? Please explain your answer in 2-3 sentences. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer goes here*\n",
    "No, according to the sccater plot,there is no There is no obvious proportional relationship  between price and the engine-power. There are a lot of outliers in the plot, which may cause influence to our judgement and there is a parabolic relationship between the price and engine-power.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.6 --- [2 marks] ==========\n",
    "Visualise the distribution of the car prices. Choose a sensible value for the number of bins in the histogram. Again, label axes appropriately and include a title in your plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAETCAYAAADah9Z7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niKEvSQX5//yBqP5nKzjHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117300990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your code goes here\n",
    "plt.hist(auto_numeric['price'], bins=15)  # arguments are passed to np.histogram\n",
    "plt.title(\"Histogram of price with 15 bins\")\n",
    "plt.xlabel('price', color = 'g')\n",
    "plt.ylabel('number', color = 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.7 --- [2 marks] ==========\n",
    "How could you preprocess the data to improve the performance of linear regression? Don’t do it at this stage, but instead in one sentence explain why you would do what you suggested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer goes here*\n",
    "I will remove the outliers in the data for the first step, cause linear regression is very sensitive to outliers which may have big influence on the results. Remove the outliers to improve the performance of linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.8 --- [1 mark] ==========\n",
    "Now we want to build a simple linear regression model. First we need to define our input and target variables. Store the values of the attribute `engine-power` in a vector `X` and the values of our target variable `price` in a vector `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (159,)\n",
      "y shape: (159,)\n"
     ]
    }
   ],
   "source": [
    "# Your code goes here\n",
    "X = auto_numeric['engine-power'].as_matrix() \n",
    "y = auto_numeric['price'].as_matrix()\n",
    "print('X shape: {}'.format(np.shape(X)))\n",
    "print('y shape: {}'.format(np.shape(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.9 --- [1 mark] ==========\n",
    "For technical reasons, we need to convert `X` into a 2D array, otherwise we will receive an error when trying to use it for building models. Perform this transformation and confirm that the shape of the resulting array is (`n`,1) where `n` is the number of instances in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 102000.],\n",
       "       [ 115000.],\n",
       "       [  70000.],\n",
       "       [ 140000.],\n",
       "       [ 101000.],\n",
       "       [ 101000.],\n",
       "       [ 121000.],\n",
       "       [ 134000.],\n",
       "       [  48000.],\n",
       "       [  70000.],\n",
       "       [  70000.],\n",
       "       [ 176000.],\n",
       "       [  68000.],\n",
       "       [ 102000.],\n",
       "       [ 162000.],\n",
       "       [  68000.],\n",
       "       [  68000.],\n",
       "       [  88000.],\n",
       "       [ 145000.],\n",
       "       [  58000.],\n",
       "       [  76000.],\n",
       "       [  60000.],\n",
       "       [  76000.],\n",
       "       [  76000.],\n",
       "       [ 121000.],\n",
       "       [  90000.],\n",
       "       [  86000.],\n",
       "       [  86000.],\n",
       "       [ 140000.],\n",
       "       [  86000.],\n",
       "       [  94000.],\n",
       "       [  76000.],\n",
       "       [ 176000.],\n",
       "       [  68000.],\n",
       "       [  92000.],\n",
       "       [  68000.],\n",
       "       [  68000.],\n",
       "       [  68000.],\n",
       "       [  84000.],\n",
       "       [  73000.],\n",
       "       [  84000.],\n",
       "       [ 101000.],\n",
       "       [  84000.],\n",
       "       [ 120000.],\n",
       "       [ 123000.],\n",
       "       [  62000.],\n",
       "       [ 123000.],\n",
       "       [ 123000.],\n",
       "       [ 155000.],\n",
       "       [  68000.],\n",
       "       [  68000.],\n",
       "       [  68000.],\n",
       "       [ 102000.],\n",
       "       [ 116000.],\n",
       "       [  69000.],\n",
       "       [  85000.],\n",
       "       [  88000.],\n",
       "       [ 116000.],\n",
       "       [ 116000.],\n",
       "       [  70000.],\n",
       "       [  55000.],\n",
       "       [  69000.],\n",
       "       [  48000.],\n",
       "       [  69000.],\n",
       "       [  69000.],\n",
       "       [  69000.],\n",
       "       [  69000.],\n",
       "       [  69000.],\n",
       "       [  69000.],\n",
       "       [  97000.],\n",
       "       [  97000.],\n",
       "       [ 152000.],\n",
       "       [  70000.],\n",
       "       [ 152000.],\n",
       "       [ 160000.],\n",
       "       [ 200000.],\n",
       "       [  92000.],\n",
       "       [  48000.],\n",
       "       [  95000.],\n",
       "       [  95000.],\n",
       "       [  62000.],\n",
       "       [  97000.],\n",
       "       [  95000.],\n",
       "       [ 142000.],\n",
       "       [  68000.],\n",
       "       [ 112000.],\n",
       "       [  68000.],\n",
       "       [  94000.],\n",
       "       [  68000.],\n",
       "       [  88000.],\n",
       "       [ 143000.],\n",
       "       [ 110000.],\n",
       "       [ 110000.],\n",
       "       [ 110000.],\n",
       "       [ 176000.],\n",
       "       [ 160000.],\n",
       "       [  69000.],\n",
       "       [ 111000.],\n",
       "       [ 114000.],\n",
       "       [  73000.],\n",
       "       [  82000.],\n",
       "       [  82000.],\n",
       "       [  94000.],\n",
       "       [  82000.],\n",
       "       [ 116000.],\n",
       "       [  76000.],\n",
       "       [ 106000.],\n",
       "       [  52000.],\n",
       "       [ 111000.],\n",
       "       [ 102000.],\n",
       "       [  62000.],\n",
       "       [  95000.],\n",
       "       [  62000.],\n",
       "       [  62000.],\n",
       "       [  62000.],\n",
       "       [  70000.],\n",
       "       [ 161000.],\n",
       "       [  60000.],\n",
       "       [  56000.],\n",
       "       [ 176000.],\n",
       "       [ 134000.],\n",
       "       [  70000.],\n",
       "       [  70000.],\n",
       "       [  70000.],\n",
       "       [ 112000.],\n",
       "       [ 106000.],\n",
       "       [ 116000.],\n",
       "       [ 162000.],\n",
       "       [  86000.],\n",
       "       [ 143000.],\n",
       "       [ 116000.],\n",
       "       [ 116000.],\n",
       "       [  48000.],\n",
       "       [  73000.],\n",
       "       [  92000.],\n",
       "       [  92000.],\n",
       "       [  92000.],\n",
       "       [ 156000.],\n",
       "       [ 161000.],\n",
       "       [ 156000.],\n",
       "       [ 200000.],\n",
       "       [  85000.],\n",
       "       [  52000.],\n",
       "       [  85000.],\n",
       "       [  60000.],\n",
       "       [ 116000.],\n",
       "       [ 100000.],\n",
       "       [  90000.],\n",
       "       [  68000.],\n",
       "       [ 114000.],\n",
       "       [ 110000.],\n",
       "       [ 114000.],\n",
       "       [ 116000.],\n",
       "       [ 162000.],\n",
       "       [ 114000.],\n",
       "       [ 160000.],\n",
       "       [ 134000.],\n",
       "       [ 106000.],\n",
       "       [ 114000.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code goes here\n",
    "ncols = X.shape[0]\n",
    "X2 = np.reshape(X,(-1,ncols))\n",
    "X2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.10 --- [1 mark] ==========\n",
    "Now we want to use Hold-out validation to split the dataset into training and testing subsets. Use 80% of the data for training and the remaining 20% for testing. Store your data into matrices `X_train`, `X_test`, `y_train`, `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances in X: 159\n",
      "Number of instances in X_train: 127\n",
      "Number of instances in X_test: 32\n",
      "Number of instances in X_train and X_test together: 159\n"
     ]
    }
   ],
   "source": [
    "# Your code goes here\n",
    "X_train, X_test, y_train, y_test = train_test_split(X2, y, train_size = 0.8, test_size=0.2, random_state=0)\n",
    "print('Number of instances in X: {}'.format(np.shape(X2)[0]))\n",
    "print('Number of instances in X_train: {}'.format(X_train.shape[0]))\n",
    "print('Number of instances in X_test: {}'.format(X_test.shape[0]))\n",
    "print('Number of instances in X_train and X_test together: {}'.format(X_train.shape[0] + X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.11 --- [2 marks] ==========\n",
    "By using Scikit-learn's [`LinearRegression`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) fit a model to the training data. When initialising the model, set the `normalize` parameter to `True` and use default settings for the other parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.202\n"
     ]
    }
   ],
   "source": [
    "# Your code goes here\n",
    "lm = LinearRegression(fit_intercept=True, normalize=True, copy_X=True)\n",
    "lm.fit(X_train, y_train)\n",
    "print('Training accuracy: {:.3f}'.format(lm.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.12 --- [2 marks] ==========\n",
    "By looking into the attributes of your model, write down an equation for predicting the price of a car given the engine-power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction of training data: [ 10463.25232339  13249.65283399   8935.22623693   9025.11012437\n",
      "   7497.08403791   9654.29733644   8395.9229123   10732.90398571\n",
      "  11991.27840985  17204.54388129  12800.23339679  10553.13621083\n",
      "  12350.8139596   10193.60066107   8935.22623693  10193.60066107\n",
      "  15856.28556971  12800.23339679  11272.20731034  16485.47278178\n",
      "  14867.56280788   9114.99401181   8395.9229123   13609.18838374\n",
      "  16485.47278178   9114.99401181  12710.34950936   7137.54848816\n",
      "  17384.31165617  11811.51063497   9025.11012437  12710.34950936\n",
      "  18642.68608031  13249.65283399  10463.25232339  12350.8139596\n",
      "   9114.99401181   8935.22623693  13069.88505911  12710.34950936\n",
      "   9025.11012437   7856.61958767  12350.8139596   11541.85897265\n",
      "   8935.22623693  16755.1244441   11991.27840985  17294.42776873\n",
      "   9654.29733644  11362.09119778   9654.29733644   8935.22623693\n",
      "  11362.09119778  11991.27840985  11092.43953546  15406.86613252\n",
      "  13069.88505911  11092.43953546  13699.07227118   9025.11012437\n",
      "  20799.89937884   8935.22623693   8395.9229123    8935.22623693\n",
      "   9114.99401181  17384.31165617   9114.99401181  12710.34950936\n",
      "  11092.43953546  13878.84004606  18642.68608031  11272.20731034\n",
      "   8935.22623693  13249.65283399  11901.39452241  17204.54388129\n",
      "   9025.11012437  13159.76894655  15676.51779483  10912.67176058\n",
      "  10373.36843595   9654.29733644  11901.39452241  16845.00833153\n",
      "  10732.90398571  17294.42776873  13249.65283399  10373.36843595\n",
      "  11901.39452241  13249.65283399  13249.65283399  12890.11728423\n",
      "  11991.27840985  11092.43953546  15406.86613252  10463.25232339\n",
      "   8395.9229123    9654.29733644   9384.64567413  17384.31165617\n",
      "  16845.00833153  18642.68608031  10553.13621083   9384.64567413\n",
      "  11362.09119778  11362.09119778   9114.99401181  13069.88505911\n",
      "   9114.99401181   7137.54848816  10912.67176058  11541.85897265\n",
      "  13069.88505911  13069.88505911   9384.64567413  13249.65283399\n",
      "  20799.89937884   8935.22623693  11541.85897265  11272.20731034\n",
      "   8935.22623693   8216.15513742   9114.99401181  10193.60066107\n",
      "   9025.11012437   8216.15513742  13878.84004606]\n"
     ]
    }
   ],
   "source": [
    "# Your code goes here\n",
    "\n",
    "prediction_train = lm.predict(X=X_train)\n",
    "print('Prediction of training data:',prediction_train)\n",
    "price_predict = prediction_train  # y = the model's predicted values on training inputs\n",
    "# y = w0+w1x1+w2x2+...+wDxD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.13 --- [3 marks] ==========\n",
    "What happens to the price as one more unit of engine-power is added? By examining the magnitude of the regression coefficient is it possible to tell whether or not engine-power is an important influential variable on price? Explain your answer in 1-2 sentences.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer goes here*\n",
    "The price rises engine-power then when the engine-power reaches a certain value the price begin to fall.\n",
    "The accuracy score represents the coefficient of determination. This is at max 1, but can be negative. It will be 0 if you predict the mean of y for all observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.14 --- [2 marks] ==========\n",
    "Produce a scatter plot similar to the one in Question 1.4 but use training data only this time. Add the regression line to the plot and show the predictions on the training set by using a different marker. Label axes appropriately and add a title to the graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected 1D vector for x",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-c0cd16052b38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"price against engine-power of training data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolyfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoly1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolyfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/a/anaconda/lib/python2.7/site-packages/numpy/lib/polynomial.pyc\u001b[0m in \u001b[0;36mpolyfit\u001b[0;34m(x, y, deg, rcond, full, w, cov)\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"expected deg >= 0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"expected 1D vector for x\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"expected non-empty vector for x\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected 1D vector for x"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf0AAAGHCAYAAAC6dYsvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nP4Ep1Jn9hHgKAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11731d690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your code goes here\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(X_train, y_train)\n",
    "plt.xlabel('engine-power', color = 'g')\n",
    "plt.ylabel('price', color = 'r')\n",
    "plt.title(\"price against engine-power of training data\", size=20)\n",
    "axes = plt.gca()\n",
    "m, b = np.polyfit(X_train, y_train, 1)\n",
    "x = np.array(X_train)\n",
    "plt.plot(np.unique(x), np.poly1d(np.polyfit(x, y, 1))(np.unique(x)))\n",
    "\n",
    "#plt.plot(X_plot, m*X_plot + b, '-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.15 --- [2 marks] ==========\n",
    "So far we have used Hold-out validation. Can you think of a disadvantage of using this method, especially when dealing with small datasets?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer goes here*\n",
    "In problems where we have a sparse dataset we may not be able to afford the “luxury” of setting aside a portion of the dataset for testing.Since it is a single train-and-test experiment, the holdout estimate of error rate will be misleading if we happen to get an “unfortunate” split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.16 --- [1 mark] ==========\n",
    "Now we want to use k-fold cross-validation to evaluate the performance of the regression model. Famliriase yourself with the sklearn method [`KFold`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) and make sure you understand the differences between Hold-out and K-fold cross-validation. By using Scikit-learn's [`KFold`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) class construct a 5-fold cross-validation object. Set the `shuffle` parameter to `True` and `random_state` to `0`. Use the object to print the training and validation indices for the `auto_numeric` dataset (hint: see the `split` method)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_X: [  0   1   2   3   4   5   6   9  10  11  12  13  14  15  16  17  18  20\n",
      "  21  22  23  25  27  28  29  30  31  32  34  35  36  38  39  41  42  43\n",
      "  46  47  48  49  50  51  52  53  55  57  58  64  65  66  67  68  69  70\n",
      "  71  72  73  74  75  76  77  78  79  80  81  82  84  87  88  89  91  92\n",
      "  93  94  96  97  98  99 100 101 102 103 104 105 106 107 108 109 111 112\n",
      " 113 114 115 116 117 118 121 122 123 124 125 127 129 130 132 133 135 136\n",
      " 137 138 139 140 141 143 145 146 147 149 150 151 152 153 154 155 156 157\n",
      " 158] TEST_X: [  7   8  19  24  26  33  37  40  44  45  54  56  59  60  61  62  63  83\n",
      "  85  86  90  95 110 119 120 126 128 131 134 142 144 148]\n",
      "TRAIN_X: [  0   1   3   4   5   6   7   8   9  11  12  13  14  15  17  19  20  21\n",
      "  23  24  25  26  28  29  31  32  33  34  35  36  37  38  39  40  41  42\n",
      "  44  45  46  47  48  49  50  52  53  54  55  56  57  58  59  60  61  62\n",
      "  63  64  65  67  68  69  70  72  75  76  77  78  79  81  82  83  84  85\n",
      "  86  87  88  90  91  92  94  95  98  99 102 103 104 105 106 110 111 112\n",
      " 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 131 133\n",
      " 134 135 136 137 138 139 140 141 142 144 145 147 148 149 151 152 154 155\n",
      " 158] TEST_X: [  2  10  16  18  22  27  30  43  51  66  71  73  74  80  89  93  96  97\n",
      " 100 101 107 108 109 113 130 132 143 146 150 153 156 157]\n",
      "TRAIN_X: [  0   1   2   4   5   7   8   9  10  11  14  16  17  18  19  21  22  24\n",
      "  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42\n",
      "  43  44  45  46  47  51  53  54  55  56  57  58  59  60  61  62  63  65\n",
      "  66  67  70  71  72  73  74  77  79  80  81  82  83  85  86  87  88  89\n",
      "  90  91  93  95  96  97  99 100 101 102 103 104 105 107 108 109 110 113\n",
      " 114 115 116 117 119 120 121 123 124 126 127 128 129 130 131 132 133 134\n",
      " 136 137 139 140 142 143 144 146 147 148 149 150 151 152 153 154 155 156\n",
      " 157] TEST_X: [  3   6  12  13  15  20  23  48  49  50  52  64  68  69  75  76  78  84\n",
      "  92  94  98 106 111 112 118 122 125 135 138 141 145 158]\n",
      "TRAIN_X: [  2   3   6   7   8   9  10  12  13  15  16  18  19  20  21  22  23  24\n",
      "  25  26  27  29  30  31  32  33  36  37  39  40  43  44  45  47  48  49\n",
      "  50  51  52  54  56  58  59  60  61  62  63  64  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  92  93  94  95  96  97  98  99 100 101 103 106 107 108 109 110 111\n",
      " 112 113 114 115 117 118 119 120 122 125 126 127 128 130 131 132 133 134\n",
      " 135 138 139 140 141 142 143 144 145 146 148 149 150 151 153 154 156 157\n",
      " 158] TEST_X: [  0   1   4   5  11  14  17  28  34  35  38  41  42  46  53  55  57  65\n",
      "  91 102 104 105 116 121 123 124 129 136 137 147 152 155]\n",
      "TRAIN_X: [  0   1   2   3   4   5   6   7   8  10  11  12  13  14  15  16  17  18\n",
      "  19  20  22  23  24  26  27  28  30  33  34  35  37  38  40  41  42  43\n",
      "  44  45  46  48  49  50  51  52  53  54  55  56  57  59  60  61  62  63\n",
      "  64  65  66  68  69  71  73  74  75  76  78  80  83  84  85  86  89  90\n",
      "  91  92  93  94  95  96  97  98 100 101 102 104 105 106 107 108 109 110\n",
      " 111 112 113 116 118 119 120 121 122 123 124 125 126 128 129 130 131 132\n",
      " 134 135 136 137 138 141 142 143 144 145 146 147 148 150 152 153 155 156\n",
      " 157 158] TEST_X: [  9  21  25  29  31  32  36  39  47  58  67  70  72  77  79  81  82  87\n",
      "  88  99 103 114 115 117 127 133 139 140 149 151 154]\n",
      "TRAIN_y: [  0   1   2   3   4   5   6   9  10  11  12  13  14  15  16  17  18  20\n",
      "  21  22  23  25  27  28  29  30  31  32  34  35  36  38  39  41  42  43\n",
      "  46  47  48  49  50  51  52  53  55  57  58  64  65  66  67  68  69  70\n",
      "  71  72  73  74  75  76  77  78  79  80  81  82  84  87  88  89  91  92\n",
      "  93  94  96  97  98  99 100 101 102 103 104 105 106 107 108 109 111 112\n",
      " 113 114 115 116 117 118 121 122 123 124 125 127 129 130 132 133 135 136\n",
      " 137 138 139 140 141 143 145 146 147 149 150 151 152 153 154 155 156 157\n",
      " 158] TEST_y: [  7   8  19  24  26  33  37  40  44  45  54  56  59  60  61  62  63  83\n",
      "  85  86  90  95 110 119 120 126 128 131 134 142 144 148]\n",
      "TRAIN_y: [  0   1   3   4   5   6   7   8   9  11  12  13  14  15  17  19  20  21\n",
      "  23  24  25  26  28  29  31  32  33  34  35  36  37  38  39  40  41  42\n",
      "  44  45  46  47  48  49  50  52  53  54  55  56  57  58  59  60  61  62\n",
      "  63  64  65  67  68  69  70  72  75  76  77  78  79  81  82  83  84  85\n",
      "  86  87  88  90  91  92  94  95  98  99 102 103 104 105 106 110 111 112\n",
      " 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 131 133\n",
      " 134 135 136 137 138 139 140 141 142 144 145 147 148 149 151 152 154 155\n",
      " 158] TEST_y: [  2  10  16  18  22  27  30  43  51  66  71  73  74  80  89  93  96  97\n",
      " 100 101 107 108 109 113 130 132 143 146 150 153 156 157]\n",
      "TRAIN_y: [  0   1   2   4   5   7   8   9  10  11  14  16  17  18  19  21  22  24\n",
      "  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42\n",
      "  43  44  45  46  47  51  53  54  55  56  57  58  59  60  61  62  63  65\n",
      "  66  67  70  71  72  73  74  77  79  80  81  82  83  85  86  87  88  89\n",
      "  90  91  93  95  96  97  99 100 101 102 103 104 105 107 108 109 110 113\n",
      " 114 115 116 117 119 120 121 123 124 126 127 128 129 130 131 132 133 134\n",
      " 136 137 139 140 142 143 144 146 147 148 149 150 151 152 153 154 155 156\n",
      " 157] TEST_y: [  3   6  12  13  15  20  23  48  49  50  52  64  68  69  75  76  78  84\n",
      "  92  94  98 106 111 112 118 122 125 135 138 141 145 158]\n",
      "TRAIN_y: [  2   3   6   7   8   9  10  12  13  15  16  18  19  20  21  22  23  24\n",
      "  25  26  27  29  30  31  32  33  36  37  39  40  43  44  45  47  48  49\n",
      "  50  51  52  54  56  58  59  60  61  62  63  64  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  92  93  94  95  96  97  98  99 100 101 103 106 107 108 109 110 111\n",
      " 112 113 114 115 117 118 119 120 122 125 126 127 128 130 131 132 133 134\n",
      " 135 138 139 140 141 142 143 144 145 146 148 149 150 151 153 154 156 157\n",
      " 158] TEST_y: [  0   1   4   5  11  14  17  28  34  35  38  41  42  46  53  55  57  65\n",
      "  91 102 104 105 116 121 123 124 129 136 137 147 152 155]\n",
      "TRAIN_y: [  0   1   2   3   4   5   6   7   8  10  11  12  13  14  15  16  17  18\n",
      "  19  20  22  23  24  26  27  28  30  33  34  35  37  38  40  41  42  43\n",
      "  44  45  46  48  49  50  51  52  53  54  55  56  57  59  60  61  62  63\n",
      "  64  65  66  68  69  71  73  74  75  76  78  80  83  84  85  86  89  90\n",
      "  91  92  93  94  95  96  97  98 100 101 102 104 105 106 107 108 109 110\n",
      " 111 112 113 116 118 119 120 121 122 123 124 125 126 128 129 130 131 132\n",
      " 134 135 136 137 138 141 142 143 144 145 146 147 148 150 152 153 155 156\n",
      " 157 158] TEST_y: [  9  21  25  29  31  32  36  39  47  58  67  70  72  77  79  81  82  87\n",
      "  88  99 103 114 115 117 127 133 139 140 149 151 154]\n"
     ]
    }
   ],
   "source": [
    "# Your code goes here\n",
    "from sklearn.model_selection import KFold \n",
    "kf = KFold(n_splits=5, random_state=0, shuffle=True)\n",
    "for train_index, test_index in kf.split(X2):\n",
    "     print(\"TRAIN_X:\", train_index, \"TEST_X:\", test_index)\n",
    "        \n",
    "for train_index, test_index in kf.split(y):\n",
    "     print(\"TRAIN_y:\", train_index, \"TEST_y:\", test_index)  \n",
    "     \n",
    "        \n",
    "        \n",
    "#X_train, X_test = X[train_index], X[test_index]\n",
    "#y_train, y_test = y[train_index], y[test_index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.17 --- [3 marks] ==========\n",
    "By making use of the iterator you constructed in the previous question, loop through the 5 folds and display the mean value of the `price` variable for the training instances in each fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1, 159]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-92a1c4404fc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Your code goes here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[fold {0}] mean: {1:.5f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/a/anaconda/lib/python2.7/site-packages/sklearn/model_selection/_split.pyc\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mtesting\u001b[0m \u001b[0mset\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthat\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \"\"\"\n\u001b[0;32m--> 314\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/a/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/a/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 181\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1, 159]"
     ]
    }
   ],
   "source": [
    "# Your code goes here\n",
    "for k, (train, test) in enumerate(kf.split(X, y)):\n",
    "    mean = np.mean(y[train])    \n",
    "print(\"[fold {0}] mean: {1:.5f}\".format(k, mean))\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.18 --- [3 marks] ==========\n",
    "Now initialise a new `LinearRegression` model and fit it by making use of the cross-validation iterator, the `X` and `y` arrays defined above and the [`cross_val_predict`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html) function. Display the shape of your prediction and confirm it has the same dimensionality as your `y` vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1, 159]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-bda74afb377f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_val_predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlasso\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLasso\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlasso\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mlasso_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/a/anaconda/lib/python2.7/site-packages/sklearn/model_selection/_validation.pyc\u001b[0m in \u001b[0;36mcross_val_predict\u001b[0;34m(estimator, X, y, groups, cv, n_jobs, verbose, fit_params, pre_dispatch, method)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlasso\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \"\"\"\n\u001b[0;32m--> 385\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/a/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/a/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 181\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1, 159]"
     ]
    }
   ],
   "source": [
    "# Your code goes here\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "lasso = linear_model.Lasso()\n",
    "lasso_cv = LassoCV(alphas=alphas, random_state=0)\n",
    "y_pred = cross_val_predict(lasso, X, y)\n",
    "for k, (train, test) in enumerate(kf.split(X, y)):\n",
    "    lasso_cv.fit(X[train], y[train])\n",
    "    print(\"[fold {0}] alpha: {1:.5f}, score: {2:.5f}\".\n",
    "          format(k, lasso_cv.alpha_, lasso_cv.score(X[test], y[test])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.19 --- [2 marks] ==========\n",
    "Report the Coefficient of Determination (R^2), Root Mean Squared Error (RMSE), Mean Absolute Error (MAE) and Correlation Coefficient (CC) from the simple linear regression model you build in Question 1.18. *Hint: RMSE is the square root of the Mean Squared Error (MSE). For CC you might find numpy's [`corrcoef`](http://docs.scipy.org/doc/numpy/reference/generated/numpy.corrcoef.html) function useful.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.20 --- [4 marks] ==========\n",
    "What do the above metrics intend to measure? Relate the values of CC, MAE and RMSE to the observations you made in Question 1.5. Explain your answer in 1-2 short paragraphs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer goes here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.21 --- [3 marks] ==========\n",
    "Show a histogram of the residuals of the linear regression model (i.e. true - predicted values). Label axes appropriately and add a title to your plot. Does the distribution of residuals look like what you expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer goes here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.22 --- [2 marks] ==========\n",
    "Load the new dataset `train_auto_base.csv` into a pandas DataFrame `auto_base`. Again by using the `engine-power` attribute as predictor and `price` as target variable build a LinearRegression model on this dataset. Report the R^2, RMSE, MAE and CC metrics for this model by making use of the K-fold CV iterator constructed in Question 1.16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.23 --- [2 marks] ==========\n",
    "Show a scatter plot of predicted vs. true prices and another one of predicted price vs. engine-power. Use a single plot with two subplots. Label axes appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.24 --- [3 marks] ==========\n",
    "What is the simplest baseline model for the purposes of regression? Relate your answer to the regression model you have just built as part of this question. Can the predictions of this model be justified given the procedure you followed to train it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer goes here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.25 --- [2 marks] ==========\n",
    "Why do you think this model performs so poorly? (*Hint: Justify your answer by displaying some statistics about the `auto_base` dataset.*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer goes here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Multivariate Linear Regression [50%]\n",
    "In this Section we will fit a Multivariate Linear Regression model (LinearRegression) to the dataset. In contrast to Part 1, we will now train a model with multiple explanatory variables and ascertain how they affect our ability to predict the retail price of a car. One of our foremost concerns will be to determine exactly which attributes to include in the model and which may be left out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.1 --- [10 marks] ==========\n",
    "Use the original dataset (`auto_numeric`) and a visualisation tool of your choice to examine whether or not any of the other attributes are particularly good at predicting the price. Can you find any? Do any attributes appear useless at predicting the price? Do any attributes exhibit significant correlations? As you answer these questions, list two attributes for each question but do not modify the dataset at this stage. Of the attributes you listed, which ones could you safely remove? Explain in 4-5 sentences. *Hint: you might find seaborn's [`pairplot`](https://seaborn.github.io/generated/seaborn.pairplot.html?highlight=pairplot#seaborn.pairplot) function useful for this question.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer goes here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.2 --- [3 marks] ==========\n",
    "We will now make a first attempt at building a Multivariate Linear Regression model using all numeric attributes. Initialise a `LinearRegression` model and predict the output by using 5-fold cross-validation and the `cross_val_predict` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.3 --- [2 marks] ==========\n",
    "Display the Root Mean Squared Error (RMSE), Mean Absolute Error (MAE) and Correlation Coefficient (CC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.4 --- [2 marks] ==========\n",
    " Comment on each metric display above in comparison to what you have obtained for the Simple Linear Regression model in Question 1.19."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer goes here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.5 --- [2 marks] ==========\n",
    "Examine the histogram for the `engine-size` attribute. Choose a sensible value for the number of bins in the histogram. Label axes appropriately and include a title in your plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.6 --- [2 marks] ==========\n",
    "Is the distribution expected to cause a problem for regression? Explain your answer in 2-3 sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer goes here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.7 --- [3 marks] ==========\n",
    "Transform this attribute using an appropriate simple technique from the lectures. Plot the histogram of the transformed attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.8 --- [3 marks] ==========\n",
    "Now re-build a Linear Regression model on the transformed dataset and report the R^2, RMSE, MAE and CC metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.9 --- [3 marks] ==========\n",
    "How has the performance of your model changed? Explain your answer in 1-2 sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer goes here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.10 --- [2 marks] ==========\n",
    "So far we have performed regression with numeric attributes. We will now attempt to integrate nominal (categorical) attributes into our regression model. \n",
    "Load the dataset `train_auto_full.csv` into a pandas DataFrame called `auto_full`. Display the number of samples and attributes in the dataset. Also, display the first 20 instances of the dataset. *Hint: Execute the cell below to change the default for `max_columns` display option in pandas.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('max_columns', 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.11 --- [3 marks] ==========\n",
    "This dataset contains a mixture of numeric and nominal attributes. Name the variables that you think are categorical. Why can we not use the nominal attributes in their current form for the purposes of regression? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer goes here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.12 --- [5 marks] ==========\n",
    "Now we want to convert the categorical variables by using [One-Hot-Encoding](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder). Familiarise yourself with the class. One limitation with this module is that it can deal only with categorical attributes in integer format (remember that in our example we have attributes in string format). \n",
    "\n",
    "Copy the `auto_full` dataframe into a new dataframe `auto_full_edit` and transform the categorical variables by using [Label Encoding](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html). Then transform again the categorical variables by using One-Hot-Encoding. Make sure you don't transform the continuous variables. *Hint: make appropriate use of the `categorical_features` parameter in [`OneHotEncoder`](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder).*\n",
    "\n",
    "Store the transformed attributes into a numpy array `X_enc` and display its dimensionality.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.13 --- [2 marks] ==========\n",
    "By using the transformed data train a multivariate linear regression model and by using 5-fold cross-validation report the R^2, RMSE, MAE and CC metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.14 --- [4 marks] ==========\n",
    "How does this more complex model perform with respect to your best performing model from either question 2.3 or 2.8? List one advantage and one disadvantage of using the more complex model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer goes here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.15 --- [4 marks] ==========\n",
    "Finally, experiment with tree-based regressors (e.g. [`DecisionTreeRegressor`](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html), [`RandomForestRegressor`](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)) and report 5-fold cross-validation scores for R^2, RMSE, MAE and CC. Has your performance improved? Explain your answer in 1-2 sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer goes here*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
